{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO25FPKD17BJKluPkdkfe81",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sai-bharghav/Text-Classifier/blob/main/Text_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import modules"
      ],
      "metadata": {
        "id": "CngermGdFGNR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CF_4LEkc3tQd"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('all')"
      ],
      "metadata": {
        "id": "MUwSVOXr39Cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import the data"
      ],
      "metadata": {
        "id": "arkdBPv0FMsA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset we are working on is from the [Github](https://github.com/futurexskill/ml-model-deployment/blob/main/Restaurant_Reviews.tsv.txt) and the raw link for it is [here](https://raw.githubusercontent.com/futurexskill/ml-model-deployment/main/Restaurant_Reviews.tsv.txt)"
      ],
      "metadata": {
        "id": "5ybqI4PB4A63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/futurexskill/ml-model-deployment/main/Restaurant_Reviews.tsv.txt',delimiter='\\t', quoting = 3)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "sjK8JjJO4sfC",
        "outputId": "37faaa3d-65e1-4412-ce32-66f345898405"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              Review  Liked\n",
              "0                           Wow... Loved this place.      1\n",
              "1                                 Crust is not good.      0\n",
              "2          Not tasty and the texture was just nasty.      0\n",
              "3  Stopped by during the late May bank holiday of...      1\n",
              "4  The selection on the menu was great and so wer...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-68f27319-ba0f-4d33-a29b-b216b47143bb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Liked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow... Loved this place.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Crust is not good.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Not tasty and the texture was just nasty.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-68f27319-ba0f-4d33-a29b-b216b47143bb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-68f27319-ba0f-4d33-a29b-b216b47143bb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-68f27319-ba0f-4d33-a29b-b216b47143bb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5edfc17f-4b6e-4536-945a-2f52d20d0887\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5edfc17f-4b6e-4536-945a-2f52d20d0887')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5edfc17f-4b6e-4536-945a-2f52d20d0887 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1000,\n  \"fields\": [\n    {\n      \"column\": \"Review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 996,\n        \"samples\": [\n          \"They were excellent.\",\n          \"Your servers suck, wait, correction, our server Heimer sucked.\",\n          \"Will be back again!\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Liked\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In NLP we have words like a, an, the etc. They will not tell us whether the sentence is positive or negative but these words will occupy space. These words are called as **Stop words**\n",
        "\n",
        "What are Stop words(defination)?\n",
        ">Stop words are a set of commonly used words in a language. Examples of stop words in English are “a,” “the,” “is,” “are,” etc. Stop words are commonly used in Text Mining and Natural Language Processing (NLP) to eliminate words that are so widely used that they carry very little useful information."
      ],
      "metadata": {
        "id": "tsgF8k-C47XZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "8SlPPSBr5Zk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also have some words like 'runner', 'running', 'runs' where they mean the same but are in different context. In NLP we have the concept of **Stemming** to reduce these words and complexity\n",
        "\n",
        "What is stemming?\n",
        "> Stemming is a text preprocessing technique used in natural language processing (NLP) to reduce words to their root or base form. The goal of stemming is to simplify and standardize words, which helps improve the performance of information retrieval, text classification, and other NLP tasks."
      ],
      "metadata": {
        "id": "As2XYKv95dYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.porter import PorterStemmer"
      ],
      "metadata": {
        "id": "qGsL_la-6D82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To apply these things through code we have to instanciate the Stem class"
      ],
      "metadata": {
        "id": "uwfAbEla6xFQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ps = PorterStemmer()"
      ],
      "metadata": {
        "id": "AiuAg8EM6KGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us get an idea about the dataframe and the columns we are dealing."
      ],
      "metadata": {
        "id": "grsLbTO-66HJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NE28wL_v6stz",
        "outputId": "41cc9b94-eebd-4b7e-bb81-f9e2c2620703"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Review  1000 non-null   object\n",
            " 1   Liked   1000 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 15.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nice we are dealing with two columns where there are 1000 rows and the dtype is object and int64 respectively"
      ],
      "metadata": {
        "id": "acDHR7427Cpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create the loop to build our corpus of words"
      ],
      "metadata": {
        "id": "_1W05QRwFR4n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now our plan is to loop through 1000 rows omit out the stop words and apply stemming. This will create a corpus of clean text"
      ],
      "metadata": {
        "id": "GpGmft3U6tfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = []\n",
        "import re\n",
        "\n",
        "for i in range(0,1000):\n",
        "  customer_review = re.sub('[^a-zA-Z]',' ',df['Review'][i]) # We use re library to omit out the symbols like ',' '.' and other types\n",
        "  customer_review = customer_review.lower() # Converting them into lower case\n",
        "  customer_review = customer_review.split()# We split the string into list from space as the delimiter\n",
        "\n",
        "  # We have to omit the stop words and apply stemming from the customer reviews\n",
        "  clean_review = [ps.stem(word) for word in customer_review if not word in set(stopwords.words('english'))]\n",
        "\n",
        "  # Since the output of the above code is a list, let us use join from the list and make it a string\n",
        "  clean_review = ' '.join(clean_review)\n",
        "  # Append the clean review to the corpus\n",
        "  corpus.append(clean_review)"
      ],
      "metadata": {
        "id": "s3Cdc64D7hsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wow since our loop has completed we got the corpus at the end of the cell.\n",
        "\n",
        "Let us check the first word in the corpus"
      ],
      "metadata": {
        "id": "Hl6SzIaS92BU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "h6uPwtN-86oi",
        "outputId": "2831ecdb-b431-4dfa-b549-d988d5fe72e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'wow love place'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Review'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "IrQ0g9gI9epG",
        "outputId": "382d7de6-8681-4ee9-d027-d60a5c109516"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Wow... Loved this place.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we look at the above two cells we can see that every letter is converted to lower and there is no punctuation in the corpus word"
      ],
      "metadata": {
        "id": "1CrZnuJx-AIO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert text into numerical array\n",
        "Let us convert the text into numeric array, for this we will make use of `sklearn.feature_extraction.text.TfidfVectorizer`"
      ],
      "metadata": {
        "id": "SEuKvaUq-PPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(max_features = 1500, min_df= 3, max_df=0.6)\n",
        "\n",
        "X = vectorizer.fit_transform(corpus).toarray()\n",
        "\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dG2OIknl-i4X",
        "outputId": "3b217af9-a210-406d-c460-efc9c8917304"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `min_df`: This parameter specifies the minimum number of documents in which a term (word) must appear to be included in the vocabulary. For example, if `min_df=2`, the term must appear in at least two documents to be considered. This helps in excluding very rare terms that may not carry much meaningful information.\n",
        "\n",
        "* `max_df` : This parameter specifies the maximum proportion of documents in which a term can appear to be included in the vocabulary. It can be specified as an absolute count (e.g., `max_df=5`)"
      ],
      "metadata": {
        "id": "AGS4HcE7_TFs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shape of X\n",
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdMLJkWj_u6z",
        "outputId": "d5a9e0f9-4a17-41f9-f441-29a6aec25b46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 467)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let us check a sample record and the shape of it\n",
        "X[0],X[0].shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wG_UPKO--zY1",
        "outputId": "b7537f30-6704-40a6-ca5f-299e9c3b5a6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.51611335, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.37891311, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.76814834, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        ]),\n",
              " (467,))"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the target variable and convert it into an array\n",
        "y = df.iloc[:,1].values"
      ],
      "metadata": {
        "id": "yb0ZQWtt_piZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f775JIhYABKo",
        "outputId": "8fb9744e-7ac6-4160-b88b-751d6864b26f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
              "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1,\n",
              "       0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
              "       1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1,\n",
              "       1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n",
              "       0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1,\n",
              "       0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1,\n",
              "       0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
              "       1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1,\n",
              "       0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "       0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0,\n",
              "       1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1,\n",
              "       0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
              "       1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
              "       0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1,\n",
              "       1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "       1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
              "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
              "       1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0,\n",
              "       0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
              "       0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
              "       0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n",
              "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
              "       1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1,\n",
              "       0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n",
              "       0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
              "       1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
              "       1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
              "       0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0,\n",
              "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
              "       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Split the data"
      ],
      "metadata": {
        "id": "Z1Q46_pBFo5o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us start modeling the dataset, before modeling and trying to fit a model we have to split the data into train and test datasets. For this we will make use of `train_test_split` from `sklearn.model_selection`"
      ],
      "metadata": {
        "id": "1NxSmMoaAIvh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,\n",
        "                                                 y,\n",
        "                                                 test_size=0.2,\n",
        "                                                 random_state=0)"
      ],
      "metadata": {
        "id": "QzVmPlu8AceE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can built our custom Neural network model for the classification problem above"
      ],
      "metadata": {
        "id": "cTOu_gw3Aqhq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the required modules for PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F"
      ],
      "metadata": {
        "id": "T2Un0r4FA0o6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have to convert the dtype from int to float"
      ],
      "metadata": {
        "id": "wyw_f8GbA9_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain_ = torch.from_numpy(X_train).float()\n",
        "Xtest_ = torch.from_numpy(X_test).float()\n",
        "\n",
        "ytrain_ =torch.from_numpy(y_train)\n",
        "ytest_= torch.from_numpy(y_test)"
      ],
      "metadata": {
        "id": "subVzWiOBKeU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the shape of all the tensors\n",
        "\n",
        "Xtrain_.shape,Xtest_.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7_kH_FhBeuk",
        "outputId": "f8655950-33d1-4bf0-ed0a-e9ac8c75383c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([800, 467]), torch.Size([200, 467]))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ytrain_.shape,ytest_.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uY_ei3RIBozf",
        "outputId": "3cfe04a2-158a-4217-c62b-bd3a66da3047"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([800]), torch.Size([200]))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the shapes of the tensors we can infer the parameters for neural network\n",
        "* `input_size`:467\n",
        "* `output_size`:2\n",
        "* `hidden_size`:500 ( This is our own choice)"
      ],
      "metadata": {
        "id": "yq1_TzCRBrHA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build the model"
      ],
      "metadata": {
        "id": "nHR9Lk-yFr1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self,\n",
        "               input_size:int,\n",
        "               output_size:int,\n",
        "               hidden_size:int):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(input_size,hidden_size)\n",
        "    self.fc2 = nn.Linear(hidden_size,hidden_size)\n",
        "    self.fc3 = nn.Linear(hidden_size,output_size)\n",
        "\n",
        "  def forward(self, X):\n",
        "    X = torch.relu(self.fc1(X))\n",
        "    X=torch.relu(self.fc2(X))\n",
        "\n",
        "    return F.log_softmax(X,dim=1)\n",
        "\n",
        "model = Net(467,2,500)"
      ],
      "metadata": {
        "id": "hOSFocTLCG6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the loss function and optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=0.01)\n",
        "loss_fn = nn.NLLLoss()"
      ],
      "metadata": {
        "id": "ZpwmVdluDMS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  y_pred = model(Xtrain_)\n",
        "  loss = loss_fn(y_pred,ytrain_)\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  print(f'Epoch : {epoch} | loss : {loss}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAFxgiB1DapX",
        "outputId": "d9d9d762-ac6e-4a50-c063-cd4613ec1a9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : 0 | loss : 6.18903923034668\n",
            "Epoch : 1 | loss : 5.952858924865723\n",
            "Epoch : 2 | loss : 5.662379741668701\n",
            "Epoch : 3 | loss : 5.251699924468994\n",
            "Epoch : 4 | loss : 4.698814868927002\n",
            "Epoch : 5 | loss : 3.9946401119232178\n",
            "Epoch : 6 | loss : 3.1487953662872314\n",
            "Epoch : 7 | loss : 2.229799270629883\n",
            "Epoch : 8 | loss : 1.4206492900848389\n",
            "Epoch : 9 | loss : 0.9075080156326294\n",
            "Epoch : 10 | loss : 0.6682791113853455\n",
            "Epoch : 11 | loss : 0.5627195239067078\n",
            "Epoch : 12 | loss : 0.5028825402259827\n",
            "Epoch : 13 | loss : 0.45663169026374817\n",
            "Epoch : 14 | loss : 0.41241705417633057\n",
            "Epoch : 15 | loss : 0.3703853189945221\n",
            "Epoch : 16 | loss : 0.33464598655700684\n",
            "Epoch : 17 | loss : 0.30373966693878174\n",
            "Epoch : 18 | loss : 0.27550116181373596\n",
            "Epoch : 19 | loss : 0.25167638063430786\n",
            "Epoch : 20 | loss : 0.23228786885738373\n",
            "Epoch : 21 | loss : 0.21463662385940552\n",
            "Epoch : 22 | loss : 0.19800984859466553\n",
            "Epoch : 23 | loss : 0.18350453674793243\n",
            "Epoch : 24 | loss : 0.1708034873008728\n",
            "Epoch : 25 | loss : 0.15887828171253204\n",
            "Epoch : 26 | loss : 0.14797280728816986\n",
            "Epoch : 27 | loss : 0.1386914849281311\n",
            "Epoch : 28 | loss : 0.13061697781085968\n",
            "Epoch : 29 | loss : 0.12307572364807129\n",
            "Epoch : 30 | loss : 0.11625074595212936\n",
            "Epoch : 31 | loss : 0.11041562259197235\n",
            "Epoch : 32 | loss : 0.10520444810390472\n",
            "Epoch : 33 | loss : 0.10028437525033951\n",
            "Epoch : 34 | loss : 0.09582505375146866\n",
            "Epoch : 35 | loss : 0.09193862974643707\n",
            "Epoch : 36 | loss : 0.08839236199855804\n",
            "Epoch : 37 | loss : 0.08500894904136658\n",
            "Epoch : 38 | loss : 0.08186771720647812\n",
            "Epoch : 39 | loss : 0.07902134209871292\n",
            "Epoch : 40 | loss : 0.07633762061595917\n",
            "Epoch : 41 | loss : 0.07373751699924469\n",
            "Epoch : 42 | loss : 0.07134423404932022\n",
            "Epoch : 43 | loss : 0.06920772790908813\n",
            "Epoch : 44 | loss : 0.06725139915943146\n",
            "Epoch : 45 | loss : 0.06540001183748245\n",
            "Epoch : 46 | loss : 0.06367743760347366\n",
            "Epoch : 47 | loss : 0.06213108077645302\n",
            "Epoch : 48 | loss : 0.06070055067539215\n",
            "Epoch : 49 | loss : 0.05933283641934395\n",
            "Epoch : 50 | loss : 0.05804911628365517\n",
            "Epoch : 51 | loss : 0.05687173828482628\n",
            "Epoch : 52 | loss : 0.05577395483851433\n",
            "Epoch : 53 | loss : 0.05472475662827492\n",
            "Epoch : 54 | loss : 0.05373165011405945\n",
            "Epoch : 55 | loss : 0.052800726145505905\n",
            "Epoch : 56 | loss : 0.0519174188375473\n",
            "Epoch : 57 | loss : 0.0510612353682518\n",
            "Epoch : 58 | loss : 0.05024445429444313\n",
            "Epoch : 59 | loss : 0.049480535089969635\n",
            "Epoch : 60 | loss : 0.048749107867479324\n",
            "Epoch : 61 | loss : 0.04805108159780502\n",
            "Epoch : 62 | loss : 0.047391243278980255\n",
            "Epoch : 63 | loss : 0.04677151143550873\n",
            "Epoch : 64 | loss : 0.04617997258901596\n",
            "Epoch : 65 | loss : 0.04560808837413788\n",
            "Epoch : 66 | loss : 0.04505130648612976\n",
            "Epoch : 67 | loss : 0.04451312497258186\n",
            "Epoch : 68 | loss : 0.043991878628730774\n",
            "Epoch : 69 | loss : 0.04349210858345032\n",
            "Epoch : 70 | loss : 0.04300842806696892\n",
            "Epoch : 71 | loss : 0.04254799708724022\n",
            "Epoch : 72 | loss : 0.04211297631263733\n",
            "Epoch : 73 | loss : 0.04169263318181038\n",
            "Epoch : 74 | loss : 0.041286878287792206\n",
            "Epoch : 75 | loss : 0.04089285433292389\n",
            "Epoch : 76 | loss : 0.040511440485715866\n",
            "Epoch : 77 | loss : 0.0401400551199913\n",
            "Epoch : 78 | loss : 0.03977774456143379\n",
            "Epoch : 79 | loss : 0.039425961673259735\n",
            "Epoch : 80 | loss : 0.039089057594537735\n",
            "Epoch : 81 | loss : 0.038766756653785706\n",
            "Epoch : 82 | loss : 0.0384589247405529\n",
            "Epoch : 83 | loss : 0.038143157958984375\n",
            "Epoch : 84 | loss : 0.03783314302563667\n",
            "Epoch : 85 | loss : 0.0375281386077404\n",
            "Epoch : 86 | loss : 0.03723256662487984\n",
            "Epoch : 87 | loss : 0.036959413439035416\n",
            "Epoch : 88 | loss : 0.03669675067067146\n",
            "Epoch : 89 | loss : 0.03644880652427673\n",
            "Epoch : 90 | loss : 0.03620591387152672\n",
            "Epoch : 91 | loss : 0.03597117215394974\n",
            "Epoch : 92 | loss : 0.035742729902267456\n",
            "Epoch : 93 | loss : 0.03551945090293884\n",
            "Epoch : 94 | loss : 0.03530127555131912\n",
            "Epoch : 95 | loss : 0.035089749842882156\n",
            "Epoch : 96 | loss : 0.03488394618034363\n",
            "Epoch : 97 | loss : 0.034682728350162506\n",
            "Epoch : 98 | loss : 0.03448738902807236\n",
            "Epoch : 99 | loss : 0.034299105405807495\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict on the test values"
      ],
      "metadata": {
        "id": "gQPlktdTF3En"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let us predict the Xtest_ values\n",
        "\n",
        "model.eval()\n",
        "with torch.inference_mode():\n",
        "  test_preds = model(Xtest_)\n",
        "\n",
        "  test_loss = loss_fn(test_preds,ytest_)\n",
        "\n",
        "  print(f'Test Loss | {loss}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sA4wDpzrDxqZ",
        "outputId": "3801fa90-3310-458e-e47c-b30c2e0987e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss | 0.034299105405807495\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5en34l1MEUzi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}